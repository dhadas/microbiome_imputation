{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro  \n",
    "\n",
    "Following a meeting with elhanan 03/05 i adjust the basic signal notebook accordingly.\n",
    "1. Moved some simple routines to .py files in the pycharm project.\n",
    "2. Adding LOOCV implementation\n",
    "3. Test different aspects of imputations.\n",
    "4. Measure correlations between each prediction and observed (On top of existing measurement of RMSE).\n",
    "5. Expand the tests into high/low training sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_tools\n",
    "import data_profiling_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import sklearn\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from importlib import reload, import_module\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "path = '/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019'\n",
    "data_path = path + '/PARSED_DATA/basic_process_reduce_sparse'\n",
    "out_path =  path + '/PARSED_DATA/scaleup_notebook'\n",
    "pd.options.display.max_rows = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efrat's Readme\n",
    "\n",
    "Paper: Franzosa, E. A., Sirota-Madi, A., Avila-Pacheco, J., Fornelos, N., Haiser, H. J., Reinker, S., ... & Sauk, J. S. (2019). Gut microbiome structure and metabolic activity in inflammatory bowel disease. Nature microbiology, 4(2), 293.‚Äè\n",
    "Link: https://www.nature.com/articles/s41564-018-0306-4?WT.feed_name=subjects_virology  \n",
    "\n",
    "#======================================================================\n",
    "\n",
    "Samples info: 220, human gut (IBD + Control)\n",
    "\n",
    "Excel tables taken from study supplementary.\n",
    "\n",
    "Species abundance xlsx file also includes the following metadata:\n",
    "\t- Age\n",
    "\t- Diagnosis\n",
    "\t- Fecal.Calprotectin\n",
    "...& drugs intake data:\n",
    "\t- Antibiotic\n",
    "\t- Immunosuppressant\n",
    "\t- Mesalamine\n",
    "\t- Steroids\n",
    "\n",
    "Raw data (sequences + raw untargeted metabolomics) available with accession numbers:\n",
    "- Metabolomics Workbench: PR000677\n",
    "- SRA with BioProject PRJNA400072\n",
    "\n",
    "For downloading all FASTQ files (0.6 TB), you can also use the bash script: sra_bash_script_for_fastq_download.sh \n",
    "(generated by SRA interactive explorer)\n",
    "SRA-related metadata on each sample can be found in sra_run_table.txt file (also provides the mapping between subject ID's in xlsx files & SRA sample ID's).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original sequences pre-processed can be found at : https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001204.v1.p1 (should be found but currently arent there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data has already been separted into 3 different cohorts (discovery: PRISM, validation: NLIBD, LL).  \n",
    "It was pre-processed by removing extremly sparse samples and features (basic_process_reduce_sparse notebook).  \n",
    "We continue ffrom that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgndf_PRISM = pd.read_csv(f'{data_path}/stgndf_PRISM_reduced_sparse.csv', index_col = '# Sample / Feature')\n",
    "mbdf_PRISM = pd.read_csv(f'{data_path}/mbdf_PRISM_reduced_sparse.csv', index_col = '# Sample / Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shotgun data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_profiling_tools' from '/Users/d_private/PycharmProjects/mat_imputation_demo/data_profiling_tools.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(data_profiling_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, (ax1, ax2, ax3, ax) = plt.subplots(nrows=1, ncols= 3,figsize=(16,6))\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols= 2,figsize=(12,6))\n",
    "\n",
    "# Plot sparsity per feature/Sample of new datasets\n",
    "# PRISM\n",
    "zeros = data_profiling_tools.get_spartsity_plot(stgndf_PRISM, should_plot=False)\n",
    "zeros.plot(kind='hist', ax=ax1)\n",
    "ax1.set_title('Sparsity rate per feature of PRISM shotgun data')\n",
    "\n",
    "zeros = data_profiling_tools.get_spartsity_plot(stgndf_PRISM, _ax=1 ,should_plot=False)\n",
    "zeros.plot(kind='hist', ax=ax2)\n",
    "ax2.set_title('Sparsity rate per sample of PRISM shotgun data')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metabolomics data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols= 2,figsize=(12,6))\n",
    "\n",
    "# Plot sparsity per feature/Sample of new datasets\n",
    "# PRISM\n",
    "zeros = data_profiling_tools.get_spartsity_plot(mbdf_PRISM, should_plot=False)\n",
    "zeros.plot(kind='hist', ax=ax1)\n",
    "ax1.set_title('Sparsity rate per feature of PRISM metabolomics data')\n",
    "\n",
    "zeros = data_profiling_tools.get_spartsity_plot(mbdf_PRISM, _ax=1 ,should_plot=False)\n",
    "zeros.plot(kind='hist', ax=ax2)\n",
    "ax2.set_title('Sparsity rate per sample of PRISM metabolomics data')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "path_to_dict, folds_dict = generate_folds(X, out_, 3, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/mbdf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/stgndf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/folds_180521/folds_dict.json, 1\n",
      "/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/mbdf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/stgndf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/folds_180521/folds_dict.json, 2\n",
      "/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/mbdf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/stgndf_PRISM_reduced_sparse.csv, /Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/folds_180521/folds_dict.json, 3\n"
     ]
    }
   ],
   "source": [
    "filename = f'{out_path}/params_file.txt'\n",
    "with open(filename, mode='w') as file:\n",
    "    for i in range(len(folds_dict)):\n",
    "        job_params = [path_to_X, path_to_Y, path_to_dict, str(i+1)]\n",
    "        job_params_string = \", \".join(job_params)\n",
    "        print(job_params_string)\n",
    "        file.write(job_params_string)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold_1': {'tr_idx': [52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153],\n",
       "  'ts_idx': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51]},\n",
       " 'fold_2': {'tr_idx': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153],\n",
       "  'ts_idx': [52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102]},\n",
       " 'fold_3': {'tr_idx': [0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102],\n",
       "  'ts_idx': [103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153]}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse/mbdf_PRISM_reduced_sparse.csv'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\n",
    "path_to_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement KFold / COOV and preform basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_tools\n",
    "from Transformer import Transformer as T\n",
    "\n",
    "\n",
    "def transform_X(X_tr, X_ts):\n",
    "\n",
    "    X_tr = X_tr.copy()\n",
    "    X_tr = preprocess_tools.impute_df_zeros_with_half_min(X_tr)\n",
    "    X_tr = X_tr.apply(lambda x: preprocess_tools.log_transform(x, True))\n",
    "    \n",
    "    X_ts = X_ts.copy()\n",
    "    X_ts = preprocess_tools.impute_df_zeros_with_half_min(X_ts)\n",
    "    X_ts = X_ts.apply(lambda x: preprocess_tools.log_transform(x, True))\n",
    "\n",
    "    return (X_tr, X_ts)\n",
    "\n",
    "def transform_y(y_tr, y_ts):\n",
    "    y_tr = y_tr.copy()\n",
    "    y_tr = preprocess_tools.impute_series_zeros_with_half_min(y_tr)\n",
    "    y_tr = preprocess_tools.log_transform(y_tr, True)\n",
    "    \n",
    "    y_ts = y_ts.copy()\n",
    "    y_ts = preprocess_tools.impute_series_zeros_with_half_min(y_ts)\n",
    "    y_ts = preprocess_tools.log_transform(y_ts, True)\n",
    "    return (y_tr, y_ts)\n",
    "\n",
    "# T = Transformer(transform_X, transform_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_fold(X, Y, tr_idx, ts_idx, mod):\n",
    "    \n",
    "    VERBOSE = True\n",
    "\n",
    "    preds_dict = {}\n",
    "    \n",
    "    X_tr = X.iloc[tr_idx, :]\n",
    "    X_ts = X.iloc[ts_idx, :]\n",
    "   \n",
    "    \n",
    "    X_tr, X_ts = transform_X(X_tr, X_ts)\n",
    "    X_ts = X_ts.dropna(how='all', axis='columns')\n",
    "    X_tr = X_tr[X_ts.columns]\n",
    "\n",
    "\n",
    "    for i, (otu, abundance) in enumerate(list(Y.iteritems())[:], 1):\n",
    "\n",
    "        y = abundance\n",
    "        y_tr, y_ts = y.iloc[tr_idx], y.iloc[ts_idx]\n",
    "        y_tr, y_ts = transform_y(y_tr, y_ts)\n",
    "        \n",
    "\n",
    "        # The case in which y_ts is all zeros and therefore it cannot be replaced by \n",
    "        # half minimal value and then log transformed\n",
    "        # In this case we replace y_ts with half the minimum of y_tr\n",
    "        if( y_ts.isna().sum() == y_ts.shape[0]):\n",
    "            print(\"Replacing\")\n",
    "            y_ts = y_ts.fillna(y_tr.min())\n",
    "           \n",
    "\n",
    "        # RF MODEL\n",
    "        mod.fit(X_tr, y_tr)\n",
    "\n",
    "        preds = pd.Series(data = mod.predict(X_ts), index = y_ts.index, name=f'Preds_RF')\n",
    "#         train_preds = pd.Series(data = mod.predict(X_tr), index = y_tr.index, name=f'Preds_RF')\n",
    "        \n",
    "        preds_dict[otu] = preds\n",
    "        \n",
    "\n",
    "#         compare_df = pd.DataFrame(data = [_y_test, preds], dtype=np.float64).T\n",
    "#         compare_df.rename({f'{otu}':'observed'}, inplace = True, axis = 1)\n",
    "        if i % (Y.shape[1] // 5) == 0 and VERBOSE:\n",
    "            print(f\"Finished specie {i} / {Y.shape[1]}\")\n",
    "    \n",
    "    preds_df = pd.DataFrame.from_dict(preds_dict)\n",
    "    \n",
    "    rounded_rmse = lambda pred, obs: round(RMSE(pred, obs), 4)\n",
    "    rmse = preds_df.apply(lambda col: RMSE(col, y_ts, squared=False))\n",
    "    rmse.name= 'RMSE_per_specie'\n",
    "    return (preds_df, rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### rmse_dict = {}\n",
    "mod_RF = RF(n_jobs = 8)\n",
    "# mod_Lasso = \n",
    "for j, (tr_idx, ts_idx) in enumerate(kf.split(X), 1):\n",
    "    \n",
    "    print(f\"Strating fold {j}.\")\n",
    "    preds_for_fold, rmse_for_fold = handle_fold(X, Y, tr_idx, ts_idx, mod_RF)\n",
    "    rmse_dict[f'fold_{j}'] = rmse_for_fold\n",
    "\n",
    "\n",
    "    print(f\"Finished fold {j}.\")\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_for_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_for_fold.name= 'RMSE_per_specie'\n",
    "preds_for_fold.append(rmse_for_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgndf_PRISM = pd.read_csv(f'{data_path}/stgndf_PRISM_reduced_sparse.csv', index_col = '# Sample / Feature')\n",
    "mbdf_PRISM = pd.read_csv(f'{data_path}/mbdf_PRISM_reduced_sparse.csv', index_col = '# Sample / Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_species import generate_folds, init_fold_job, local_pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = import_module('predict_species')\n",
    "reload(module)\n",
    "from predict_species import generate_folds, init_fold_job, handle_single_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/folds_180521/folds_dict.json'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/folds_180521\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Methanobrevibacter_smithii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Methanobrevibacter_smithii'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e970e66a5fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpreds_for_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_for_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_fold_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/mat_imputation_demo/predict_species.py\u001b[0m in \u001b[0;36minit_fold_job\u001b[0;34m(path_to_X, path_to_Y, path_to_folds_dict, curr_fold_num)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_FOLDS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mpreds_for_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_for_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_single_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/mat_imputation_demo/predict_species.py\u001b[0m in \u001b[0;36mhandle_single_fold\u001b[0;34m(X, Y, folds_dict, fold_num, mod)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# y = abundance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mcommon_y_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3737\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3739\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Methanobrevibacter_smithii'"
     ]
    }
   ],
   "source": [
    "# reload(predict_species)\n",
    "\n",
    "out_ =  f'{path}/PARSED_DATA/folds_180521'\n",
    "print(out_)\n",
    "path_to_dict, idx = generate_folds(X, out_, 3, False)\n",
    "\n",
    "path_to_Y = f'{data_path}/stgndf_PRISM_reduced_sparse.csv'\n",
    "path_to_X = f'{data_path}/mbdf_PRISM_reduced_sparse.csv'\n",
    "\n",
    "# init_fold_job(path_to_X, path_to_Y, path_to_dict)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    preds_for_fold, rmse_for_fold = init_fold_job(path_to_X, path_to_Y, path_to_dict, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1.\n",
      "Finished fold 1.\n",
      "Starting fold 2.\n",
      "Finished fold 2.\n",
      "Starting fold 3.\n",
      "Finished fold 3.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a6662941f48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/mat_imputation_demo/predict_species.py\u001b[0m in \u001b[0;36mlocal_pipe\u001b[0;34m(X, Y, path_to_folds_dict)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mrmse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mpreds_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only recognize index or columns for orient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     def to_numpy(\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/microbiome1/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "rmse_df, preds_df = local_pipe(X, Y, path_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (otu, abundance) in enumerate(list(Y.iteritems())[:2], 1):\n",
    "    print(i, otu)\n",
    "    print(Y_tr[otu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame.from_dict(rmse_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame.from_dict(rmse_dict)\n",
    "# rmse_df.to_csv(f'{out_path}/rmse_{NUM_FOLDS}fold_cv_transformed.csv' )\n",
    "rmse_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize prediction results \n",
    "\n",
    "Categorize data by mean relative abundance of the species and the group the results according to this and plot the mean RMSE for each bin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RMSE_per_bin(cols, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine the number of bins for mean relative abundance\n",
    "NUM_BINS = len(Y.columns)\n",
    "\n",
    "# We calculate the mean using only non-zero-samples in the original data\n",
    "mask = (Y != 0) \n",
    "rmse_df['mean_abundance'] = Y[mask].apply(lambda col: col.dropna().mean(), axis = 'index')\n",
    "rmse_df = rmse_df.sort_values(by = 'mean_abundance', ascending=False)\n",
    "\n",
    "# Map species to bins representing the rank of the mean relative abundance of the specie across samples\n",
    "labels = [f'bin_{i}' for i in range(1, NUM_BINS+1)]\n",
    "labels = list(rmse_df.index.values)\n",
    "rmse_df['abundance_rank_bin'] = pd.qcut(mean_abundance, q=NUM_BINS, labels = labels)\n",
    "fold_cols = [col for col in list(rmse_df.columns) if col.startswith('fold')]\n",
    "data = rmse_df.drop('mean_abundance', axis=1)\n",
    "# data = rmse_df.copy()\n",
    "\n",
    "# Add to each specie the mean rmse of the RF across all folds \n",
    "data['mean_specie_RMSE'] = data[fold_cols].apply(np.mean, axis =1)\n",
    "# data.head()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(80,20))\n",
    "\n",
    "sns.boxplot(x='abundance_rank_bin', y='mean_specie_RMSE', data=data)\n",
    "plt.yscale('log')\n",
    "fig.suptitle('Mean RMSE per bin (Transformed data, 30 folds RF) ',)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('log mean RMSE', fontsize=18)\n",
    "plt.ylabel('Abudance rank bin', fontsize=16)\n",
    "\n",
    "plt.savefig(f'{out_path}/RMSE_vs_10_abundance_bins_30folds.png')\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1, constrained_layout=True)\n",
    "# axs[0].plot(t1, f(t1), 'o', t2, f(t2), '-')\n",
    "# axs[0].set_title('subplot 1')\n",
    "# axs[0].set_xlabel('distance (m)')\n",
    "# axs[0].set_ylabel('Damped oscillation')\n",
    "# fig.suptitle('This is a somewhat long figure title', fontsize=16)\n",
    "\n",
    "# axs[1].plot(t3, np.cos(2*np.pi*t3), '--')\n",
    "# axs[1].set_xlabel('time (s)')\n",
    "# axs[1].set_title('subplot 2')\n",
    "# axs[1].set_ylabel('Undamped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A good exmaple of why the results are the opposite of what we hoped for  \n",
    "\n",
    "Samples that have low mean relative abundance are also usually very homogenic and so when predicting the a sample from the test data it highly resembles that train set which then leads to low RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_tools\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols= 2,figsize=(12,6))\n",
    "\n",
    "\n",
    "df1 = preprocess_tools.impute_df_zeros_with_half_min(stgndf_PRISM[['Eubacterium_rectale', 'Streptococcus_sanguinis']])\n",
    "\n",
    "df1.apply(lambda x: preprocess_tools.log_transform(x, True)).plot(kind='box', ax = ax2)\n",
    "stgndf_PRISM[['Eubacterium_rectale', 'Streptococcus_sanguinis']].plot(kind='box', ax=ax1)\n",
    "# stgndf_PRISM['Escherichia_unclassified']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations between the prediction error and the mean relative abundance rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#         df_rmse['abundance_rank_bin'] = pd.qcut(df_rmse.mean_abundance, q=i, labels=range(1,i+1))\n",
    "\n",
    "# rmse_by_bin = rmse_df.groupby('abundance_rank_bin')\n",
    "# rmse_by_bin.boxplot(subplots=False, rot=45, column=fold_columns)\n",
    "# boxplot = df.boxplot(by='X')\n",
    "\n",
    "# ax[i-2].set_title(f'{i} bins, RMSE dist per bin by abundance, ')\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(10, 2),\n",
    "                  columns=['Col1', 'Col2'])\n",
    "df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
    "                     'B', 'B', 'B', 'B', 'B'])\n",
    "df.groupby('X').apply(np.mean, axis = 1).boxplot()\n",
    "# df("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order the data by relative abundance level  \n",
    "\n",
    "We order the data with respect to the mean relative abundance of each **Specie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@param df_transformed: pd.DataFrame, row represent species (features). columns represent samples.\n",
    "@param df_untransformed: pd.DataFrame, row represent species (features). columns represent samples, \n",
    "    this dataframe contains the original relative mean abundance data before zeros were replaced.\n",
    "\n",
    "Calculate mean abundance per specie (row) while ignoring zeros\n",
    "since we replaced the zeros before transforming we will use the original data to select and remove indexes that used to be zero.\n",
    "\n",
    "'''\n",
    "def get_mean_abundance_per_specie(df_untransformed: pd.DataFrame,  df_transformed: pd.DataFrame):\n",
    "    df = df_transformed.copy().T\n",
    "    mask = df_untransformed.T != 0 \n",
    "    df['mean_abundance_post_trans'] = df[mask].apply(lambda row: row.dropna().mean(), axis = 'columns')\n",
    "    df['mean_abundance_rank'] = df.mean_abundance_post_trans.rank()\n",
    "    df = df.sort_values(by = 'mean_abundance_rank', ascending=False)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "# Add mean relative abundance per specie and a rank based on it.    \n",
    "tr_stgn_transofrmed_and_ordered = get_mean_abundance_per_specie(tr_stgn, tr_stgn_transformed.copy())\n",
    "ts_stgn_transofrmed_and_ordered = get_mean_abundance_per_specie(ts_stgn, ts_stgn_transformed.copy())\n",
    "\n",
    "\n",
    "'''\n",
    "# Sanity check \n",
    "test = pd.DataFrame(data={'A':[2, 0, 0],\n",
    "                  'B':[2,0,0],\n",
    "                  'C':[1, 0, 0]})\n",
    "\n",
    "display(test)\n",
    "test_transformed = pd.DataFrame(data={'A':[100, 100, 100],\n",
    "                  'B':[1,100,100],\n",
    "                  'C':[2, 1, 1]})\n",
    "\n",
    "get_mean_abundance_per_specie(test, test_transformed)\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Repeat the same method only by comparing the data when divided into 3 groups instead of 2:\n",
    "import regex as re\n",
    "MAX_NUM_BINS = 5\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4,figsize=(40,10))\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(2, MAX_NUM_BINS+1):\n",
    "        \n",
    "        \n",
    "#         df_rmse['abundance_rank_bin'] = pd.qcut(df_rmse.mean_abundance, q=i, labels=range(1,i+1))\n",
    "        rmse_df['abundance_rank_bin'] = pd.qcut(rmse_df.mean_abundance, q=i, labels=range(1,i+1))\n",
    "        rmse_by_bin = rmse_df.groupby('abundance_rank_bin')\n",
    "        rmse_by_bin.boxplot(subplots=False, ax=ax[i-2], rot=45, column=fold_columns)\n",
    "        ax[i-2].set_title(f'{i} bins, RMSE dist per bin by abundance, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write training, test datasets\n",
    "\n",
    "\n",
    "tr_stgn_transofrmed_and_ordered.to_csv(f'{out_path}/tr_stgn_transofrmed_and_ordered.csv',\n",
    "                       index=True, index_label=\"# Sample / Feature\")\n",
    "ts_stgn_transofrmed_and_ordered.to_csv(f'{out_path}/ts_stgn_transofrmed_and_ordered.csv', \n",
    "                       index=True, index_label=\"# Sample / Feature\")\n",
    "tr_mb_transformed.to_csv(f'{out_path}/tr_metabolome_transofrmed.csv', \n",
    "                         index=True, index_label=\"# Sample / Feature\")\n",
    "ts_mb_transformed.to_csv(f'{out_path}/ts_metabolome_transofrmed.csv',\n",
    "                         index=True, index_label=\"# Sample / Feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the predictability of high vs low abundancies by using RF & metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide shotgun data into two groups. high vs low abundancy.\n",
    "Use the metabolites data to train a RF model per each specie.\n",
    "We then test the predictability of each group using the test ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_stgn = pd.read_csv(f'{out_path}/tr_stgn_transofrmed_and_ordered.csv', index_col = '# Sample / Feature')\n",
    "ts_stgn = pd.read_csv(f'{out_path}/ts_stgn_transofrmed_and_ordered.csv', index_col = '# Sample / Feature')\n",
    "tr_mb = pd.read_csv(f'{out_path}/tr_metabolome_transofrmed.csv', index_col = '# Sample / Feature')\n",
    "ts_mb = pd.read_csv(f'{out_path}/ts_metabolome_transofrmed.csv', index_col = '# Sample / Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find main PCs of metabolome data \n",
    "\n",
    "We preform PCA to reduce dimensionality of metabolome data from a couple of thousands to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "_X = tr_mb.copy()\n",
    "_X_test = ts_mb.copy()\n",
    "mod = PCA(n_components=20)\n",
    "mod.fit(_X)\n",
    "\n",
    "_X_pcs = mod.components_\n",
    "_X_pcs.shape\n",
    "\n",
    "\n",
    "_X_PCA = mod.transform(_X)\n",
    "_X_test_PCA = mod.transform(_X_test)\n",
    "\n",
    "mod.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each strain in shotgun data, try to predict it using metabolome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = tr_mb.copy()\n",
    "_X_test = ts_mb.copy()\n",
    "\n",
    "_Y = tr_stgn.drop(['mean_abundance_post_trans', 'mean_abundance_rank'], axis = 1)\n",
    "_Y_test = ts_stgn.drop(['mean_abundance_post_trans', 'mean_abundance_rank'], axis = 1)\n",
    "\n",
    "N_species = _Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.metrics import mean_squared_error as RMSE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import namedtuple\n",
    "RMSEs = namedtuple('RMSEs', ['RF', 'Lasso', 'PCA', 'RF_PCA', 'Elastic'])\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "mod = RF(n_jobs = -1)\n",
    "lm_lasso = Lasso(max_iter = 2000)\n",
    "lm_pca = LinearRegression()\n",
    "lm_elastic = ElasticNet(max_iter = 2000)\n",
    "\n",
    "rmse_dict = {}\n",
    "\n",
    "# fig = plt.figure(figsize=(70,40))\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "\n",
    "for i, (otu, row) in enumerate(list(_Y.iterrows())[:], 1):\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"Now fitting rf regressor for specie: {otu}\")\n",
    "\n",
    "    _y = _Y.loc[otu,:]\n",
    "    _y_test = _Y_test.loc[otu,:]\n",
    "    \n",
    "\n",
    "    # RF MODEL\n",
    "        \n",
    "    mod.fit(_X, _y)\n",
    "        \n",
    "    preds = pd.Series(data = mod.predict(_X_test), index = _y_test.index, name=f'Preds_RF')\n",
    "    train_preds = pd.Series(data = mod.predict(_X), index = _y.index, name=f'Preds_RF')\n",
    "    \n",
    "\n",
    "    compare_df = pd.DataFrame(data = [_y_test, preds], dtype=np.float64).T\n",
    "    compare_df.rename({f'{otu}':'observed'}, inplace = True, axis = 1)\n",
    "    \n",
    "    # Lasso\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"Now fitting a lasso model for specie: {otu}\")\n",
    "    \n",
    "\n",
    "    lm_lasso.fit(_X, _y)\n",
    "    \n",
    "    preds = pd.Series(data = lm_lasso.predict(_X_test), index = _y_test.index, name=f'Preds_LASSO')\n",
    "    train_preds = pd.Series(data = lm_lasso.predict(_X), index = _y.index, name=f'Preds_LASSO')\n",
    "    compare_df['Preds_Lasso'] = preds\n",
    "    \n",
    "    \n",
    "    # PCA\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"Now fitting a PCA regression model for specie: {otu}\")\n",
    "    \n",
    "    lm_pca.fit(_X_PCA, _y)\n",
    "\n",
    "    \n",
    "    preds = pd.Series(data = lm_pca.predict(_X_test_PCA), index = _y_test.index, name=f'Preds_PCA')\n",
    "    train_preds = pd.Series(data = lm_pca.predict(_X_PCA),index = _y.index, name=f'Preds_PCA')\n",
    "    compare_df['Preds_PCA'] = preds\n",
    "\n",
    "    \n",
    "    # Reduced dimensionality RF\n",
    "        \n",
    "    mod.fit(_X_PCA, _y)\n",
    "        \n",
    "    preds = pd.Series(data = mod.predict(_X_test_PCA), index = _y_test.index, name=f'Preds_RF_PCA')\n",
    "    train_preds = pd.Series(data = mod.predict(_X_PCA), index = _y.index, name=f'Preds_RF_PCA')\n",
    "    compare_df['Preds_RF_PCA'] = preds\n",
    "    \n",
    "        \n",
    "    # ElasticNet\n",
    "        \n",
    "    lm_elastic.fit(_X, _y)\n",
    "        \n",
    "    preds = pd.Series(data = lm_elastic.predict(_X_test), index = _y_test.index, name=f'Preds_Elastic')\n",
    "    train_preds = pd.Series(data = lm_elastic.predict(_X), index = _y.index, name=f'Preds_Elastic')\n",
    "    compare_df['Preds_Elastic'] = preds\n",
    "\n",
    "    \n",
    "    \n",
    "    test_rmse_RF = round(RMSE(compare_df.observed, compare_df.Preds_RF, squared=False), 5)\n",
    "    test_rmse_Lasso = round(RMSE(compare_df.observed, compare_df.Preds_Lasso, squared=False), 5)\n",
    "    test_rmse_PCA = round(RMSE(compare_df.observed, compare_df.Preds_PCA, squared=False), 5)\n",
    "    test_rmse_RF_PCA = round(RMSE(compare_df.observed, compare_df.Preds_RF_PCA, squared=False), 5)\n",
    "    test_rmse_Elastic = round(RMSE(compare_df.observed, compare_df.Preds_Elastic, squared=False), 5)\n",
    "    \n",
    "    rmse_dict[otu] = RMSEs(test_rmse_RF, test_rmse_Lasso, test_rmse_PCA, test_rmse_RF_PCA, test_rmse_Elastic)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"test RMSE for RF: {test_rmse_RF}\")\n",
    "        print(f\"test RMSE for Lasso: {test_rmse_Lasso}\")\n",
    "        print(f\"test RMSE for PCA: {test_rmse_PCA}\")\n",
    "        print(f\"test RMSE for RF PCA: {test_rmse_RF_PCA}\")\n",
    "        print(f\"test RMSE for Elastic PCA: {test_rmse_Elastic}\")\n",
    "        \n",
    "    print(f\"Finished specie: {i}/{N_species}, Specie: {otu}\")\n",
    "        \n",
    "\n",
    "print(\"Finished.\")\n",
    "\n",
    "\n",
    "# plt.savefig('RF_predictor_no_train.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dig into the results\n",
    "\n",
    "RF consistently prefroms better than Lasso therefore Lasso is omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting models: RF, Lasso for each specie from metabolites, we aggregate the RMSEs, and calculate the mean RMSE for each specie with respect to it's rank in the mean abundance criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rmse = pd.DataFrame.from_dict(rmse_dict, orient='index')\n",
    "\n",
    "# mask = df_species.above_mean_abundance == True\n",
    "# upper = df_rmse[mask].apply(np.mean, axis = 0)\n",
    "# lower = df_rmse[~mask].apply(np.mean, axis = 0)\n",
    "\n",
    "# print(f\"Upper rmses:\\n{upper}\\n Lower rmses:\\n{lower}\")\n",
    "\n",
    "# df_rmse = df_rmse.sort_values(by=['RF', 'Lasso', 'PCA', 'RF_PCA', 'Elastic'], ascending=True)\n",
    "# df_rmse.to_csv(f'{out_path}/RMSEs_specie_from_metabs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same methodology, we split the data into bins and plot rmses of each bin to identify which part of the data has the lowest RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. Verify the results\n",
    "2. Iterate for multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df_rmse.mean_abundance, q =2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same method only by comparing the data when divided into 3 groups instead of 2:\n",
    "\n",
    "MAX_NUM_BINS = 5\n",
    "\n",
    "df_rmse = pd.DataFrame.from_dict(rmse_dict, orient='index')\n",
    "df_rmse['mean_abundance'] = ts_stgn.mean_abundance_post_trans\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4,figsize=(40,10))\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(2, MAX_NUM_BINS+1):\n",
    "    \n",
    "\n",
    "#         df_rmse['abundance_rank_bin'] = pd.qcut(df_rmse.mean_abundance, q=i, labels=range(1,i+1))\n",
    "        df_rmse['abundance_rank_bin'] = pd.qcut(df_rmse.mean_abundance, q=i, labels=range(1,i+1))\n",
    "        rmse_by_bin = df_rmse.groupby('abundance_rank_bin')\n",
    "        rmse_by_bin.boxplot(subplots=False, ax=ax[i-2], rot=45, column=['RF', 'Elastic'])\n",
    "        ax[i-2].set_title(f'{i} bins, RMSE dist per bin by abundance, ')\n",
    "\n",
    "\n",
    "plt.savefig(f'{out_path}/RMSEs_specie_from_metabs.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RF: \" , df_species.where(df_species.above_mean_abundance == False).test_rmse.mean())\n",
    "print(\"Lasso: \" , df_species.where(df_species.above_mean_abundance == False).test_rmse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Top covariates\n",
    "    pd.DataFrame(np.corrcoef(_y.to_numpy().astype(float), _X.to_numpy().astype(float), rowvar=False))\n",
    "    # Find all correlations\n",
    "    corr = np.corrcoef(_y.to_numpy().astype(float), df_metab.T.to_numpy().astype(float), rowvars=\n",
    "    corr = pd.DataFrame(corr, \n",
    "                        columns = [otu] + list(mbdf_PRISM.index),\n",
    "                        index = [otu] + list(mbdf_PRISM.index))\n",
    "    \n",
    "    # Step 4 - Filter out weak correlations \n",
    "    strong_corr = corr.loc[otu,:]\n",
    "    strong_corr = strong_corr.where((strong_corr < .99) & (abs(strong_corr) > CORR_THRESHOLD)).dropna()\n",
    "    strong_corr_dict[otu] = strong_corr\n",
    "    strongest_corr_dict[otu] = strong_corr.where(abs(strong_corr) == abs(strong_corr).max()).dropna()\n",
    "    \n",
    "    # If no strong correlation was found, plot a infromative texst instead of a graph and skip the rest.\n",
    "    if(len(strongest_corr_dict[otu]) == 0): \n",
    "        continue\n",
    "        ax = fig.add_subplot(9, 8, i)\n",
    "        ax.text(0.2, 0.4, f\"{otu}:\\n No strong correlations found\", fontsize=12)\n",
    "\n",
    "        \n",
    "        \n",
    "    # Prepare a unified dataframe with a column of the OTU relatvie abundances, Metabolites                 \n",
    "    is_over_q20 = row > q_20\n",
    "    df_full = pd.DataFrame(data = [row.replace(0, q_01/((row==0).sum()+1)), \n",
    "                                   mbdf_PRISM.loc[strongest_corr_dict[otu].index[0],:]])\n",
    "    df_full = df_full.T    \n",
    "        \n",
    "            \n",
    "    # Add Indicator columns for weather a samples is used or not (i.e it belongs to upper 80% or not.)\n",
    "    df_full['is_over_q20'] = is_over_q20\n",
    "    df_full['color']= np.where(is_over_q20==True , \"#9b59b6\", \"#3498db\")\n",
    "    \n",
    "    # Possible to back transform the data     \n",
    "    # df_full[otu] = df_full[otu].apply(lambda x: -1*np.log(np.sin(x**2)))\n",
    "    \n",
    "    # Step 5 - Plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Test for differential signal in each group\n",
    "Test with 3 splits instead of 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 -  by median abundance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stgndf_PRISM.apply(lambda row: ((row==0).sum()/N_SAMPLES)*100, axis = 1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((stgndf_PRISM.loc['Bacteroides_plebeius',:] == 0).sum())/N_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data according to the paper\n",
    "**From the subsection statistical analysis in the methods section of the paper:**  \n",
    "* *Each data type was analysed separately in each cohort.*\n",
    "* *Relative abundance values were log-transformed to variance-stabilize the data.*\n",
    "* *Zero values were additively smoothed by half the smallest non-zero measurement on a per-sample basis.*\n",
    "* *For both cohorts, we modelled the transformed abundance of each feature as a function of IBD phenotype (modelled as a categorical variable with ‚Äònon-IBD control‚Äô as the reference state), with age as a continuous covariate in both cohorts, and four medications (antibiotics, immunosuppressants, mesalamine and steroids) as binary covariates in the PRISM cohort.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgndf_PRISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = stgndf_PRISM.replace(0, np.nan)\n",
    "\n",
    "min_abundance_per_sample = stgndf_PRISM.apply(lambda row: row.replace(0, np.nan).dropna().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgndf_PRISM = stgndf_PRISM.astype(float)\n",
    "stgndf_PRISM_no_zeros = stgndf_PRISM.apply(lambda sample: sample.replace(0, min_abundance_per_sample[sample.name]/2))\n",
    "stgndf_PRISM_processed = stgndf_PRISM_no_zeros.apply(lambda row: -1*np.log10(row))\n",
    "# stgndf_PRISM.apply(lambda sample: sample.name)\n",
    "# stgndf_PRISM_transformed = stgndf_PRISM.apply(lambda row: -np.log10(row))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgndf_PRISM_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of important correlations between metabolites and bacteria\n",
    "1. Find correlations in general\n",
    "2. Filter weak correlations (e.g |corr| < .3) \n",
    "3. For each metabolite or specie create a dictionary with the specie or metabolies (opposite accordigly) that have strong correlation with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find correlations between 16s and metabolites (correlations between rows based on shared columns)\n",
    "# Since we'd like to use the non-zero center of the mass values to infer about the quantity of the lower values,\n",
    "# we drop the zeros and then take the upper 80% of the data for each OTU. \n",
    "# Based on these upper 80% of each OTU we search for correlations in the metabolite data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. we define a strong correlation as >.3 or <-.3 in the case of negative correlation\n",
    "CORR_THRESHOLD = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_var_specie(idx):\n",
    "    return True if idx <= N_sxs else False\n",
    "\n",
    "def extract_high_corrs(row, idx):\n",
    "    coefs = {}\n",
    "    if is_var_specie(idx):\n",
    "        coefs = row[N_sxs+1:].dropna().to_dict()\n",
    "        \n",
    "    else:\n",
    "        coefs = row[0:N_sxs].dropna().to_dict()\n",
    "    \n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "\n",
    "VERBOSE = False\n",
    "EPSILON = 0.01\n",
    "CORR_THRESHOLD = 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each specie (column in stgndf_PRISM), we:  \n",
    "1. construct a vector of non-zero samples.\n",
    "2. Take the upper 80% percent of the vector (meaning the top 80% relative abundance counts of non zero samples)\n",
    "3. Find the correlations between this samples and the same samples in the Metabolomic data (mbdf)\n",
    "4. Filter Strong correlations only - Above <CORR_THRESHOLD> and store them in strong_corr_dict  \n",
    "    a. If there are no such correlation we skip the rest\n",
    "5. We then back plot the OTU and the Metabolites using one color for samples that were used in the process of finding the correlations and other color for samples that belong to the lower 20% or either are 0s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "strong_corr_dict = {}\n",
    "strongest_corr_dict = {}\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "\n",
    "for i, (otu, row) in enumerate(list(stgndf_PRISM_processed.iterrows())[:5], 1):\n",
    "    \n",
    "    print(otu)\n",
    "    print(row)\n",
    "    '''\n",
    "    no_zeros = row.where(row > row.min())\n",
    "    print(row.min)\n",
    "    print(no_zeros)\n",
    "    q_20 = no_zeros.quantile(.8)\n",
    "    q_01 = no_zeros.quantile(.01)\n",
    "\n",
    "    ra_over_q20 = no_zeros[no_zeros.map(lambda x: x > q_20)]\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"For otu: {otu}, initial length is {len(row)}.\\n\"\n",
    "              f\"Number of zeros is: {row.apply(lambda val: val==0).sum()} \"\n",
    "              f\"Number of values above 20 percentile: {len(ra_over_q20)}\\n\")\n",
    "    \n",
    "    # Step 3 - Find all correlations\n",
    "    corr = np.corrcoef(ra_over_q20.to_numpy().astype(float), mbdf_PRISM[ra_over_q20.index].to_numpy().astype(float)) \n",
    "    corr = pd.DataFrame(corr, \n",
    "                        columns = [otu] + list(mbdf_PRISM.index),\n",
    "                        index = [otu] + list(mbdf_PRISM.index))\n",
    "    \n",
    "    # Step 4 - Filter out weak correlations \n",
    "    strong_corr = corr.loc[otu,:]\n",
    "    strong_corr = strong_corr.where((strong_corr < .99) & (abs(strong_corr) > CORR_THRESHOLD)).dropna()\n",
    "    strong_corr_dict[otu] = strong_corr\n",
    "    strongest_corr_dict[otu] = strong_corr.where(abs(strong_corr) == abs(strong_corr).max()).dropna()\n",
    "    \n",
    "    # If no strong correlation was found, plot a infromative texst instead of a graph and skip the rest.\n",
    "    if(len(strongest_corr_dict[otu]) == 0): \n",
    "        continue\n",
    "        ax = fig.add_subplot(9, 8, i)\n",
    "        ax.text(0.2, 0.4, f\"{otu}:\\n No strong correlations found\", fontsize=12)\n",
    "\n",
    "        \n",
    "        \n",
    "    # Prepare a unified dataframe with a column of the OTU relatvie abundances, Metabolites                 \n",
    "    is_over_q20 = row > q_20\n",
    "    df_full = pd.DataFrame(data = [row.replace(0, q_01/((row==0).sum()+1)), \n",
    "                                   mbdf_PRISM.loc[strongest_corr_dict[otu].index[0],:]])\n",
    "    df_full = df_full.T    \n",
    "        \n",
    "            \n",
    "    # Add Indicator columns for weather a samples is used or not (i.e it belongs to upper 80% or not.)\n",
    "    df_full['is_over_q20'] = is_over_q20\n",
    "    df_full['color']= np.where(is_over_q20==True , \"#9b59b6\", \"#3498db\")\n",
    "    \n",
    "    # Possible to back transform the data     \n",
    "    # df_full[otu] = df_full[otu].apply(lambda x: -1*np.log(np.sin(x**2)))\n",
    "    \n",
    "    # Step 5 - Plotting\n",
    "\n",
    "    ax = fig.add_subplot(1, 5, i)\n",
    "    ax.set_xlim([0, row.quantile(.95)])\n",
    "#     i+=1\n",
    "\n",
    "#     sns.regplot(x=otu, y=strongest_corr_dict[otu].index[0], data=df_full,\n",
    "#                      scatter_kws={'facecolors': df_full.color}, fit_reg=True, logx=False,\n",
    "#                 ax=ax)\n",
    "    \n",
    "    l1 = sns.regplot(x=otu, y=strongest_corr_dict[otu].index[0], data=df_full.loc[~df_full['is_over_q20']],\n",
    "#                      scatter_kws={'facecolors': df_full.color},\n",
    "            fit_reg=True, logx=False, ax=ax, truncate=False, label = 'Zeros and <q20')\n",
    "    \n",
    "    l2 = sns.regplot(x=otu, y=strongest_corr_dict[otu].index[0], data=df_full.loc[df_full['is_over_q20']],\n",
    "                fit_reg=True, logx=False, ax=ax,  truncate=False, label = '>q20, Used'\n",
    "    #                          scatter_kws={'facecolors': df_full.loc[df_full['is_over_q20']].color}\n",
    "        )\n",
    "    \n",
    "    \n",
    "    pearson_r = round(strongest_corr_dict[otu][0], 2)\n",
    "    r_squared = round(pearson_r**2, 2)\n",
    "#     txt = f\"{otu.split(';')[1]} vs. {strongest_corr_dict[otu].index[0]},\\n r: {pearson_r}, r^2: {r_squared}\"    \n",
    "    \n",
    "#     ax.title.set_text(txt)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "plt.savefig('corrs.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an RF predictor and plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tradtional train-test split 0.8:0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sxs_train, sxs_test = train_test_split(sxsdf.T, train_size = 0.8, test_size = 0.2, shuffle=True)\n",
    "train_ids = sxs_train.T.columns.intersection(sample_ids)\n",
    "test_ids = sxs_test.T.columns.intersection(sample_ids)\n",
    "\n",
    "\n",
    "sxs_train, sxs_test = sxs_train.T, sxs_test.T\n",
    "mb_train, mb_test = mbdf.loc[:,train_ids], mbdf.loc[:,test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the train-test split we end up with the following dimensions:  \n",
    "* Train - 192 samples  \n",
    "* Test - 48 samples  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.metrics import mean_squared_error as RMSE\n",
    "\n",
    "strong_corr_dict = {}\n",
    "strongest_corr_dict = {}\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "mod = RF(n_jobs = 8)\n",
    "fig = plt.figure(figsize=(70,40))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, (otu, row) in enumerate(list(sxs_train.iterrows())[:-1], 1):\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"Now building rf regressor for otu: {otu}\")\n",
    "    \n",
    "    \n",
    "    _y = row\n",
    "    _X = mb_train.T\n",
    "    \n",
    "    _y_test_observed = sxs_test.loc[otu,:]\n",
    "    _X_test = mb_test.T\n",
    "    \n",
    "    \n",
    "        \n",
    "    mod.fit(_X, _y)\n",
    "        \n",
    "    preds = pd.Series(data = mod.predict(_X_test), index = _y_test_observed.index, name=f'Preds')\n",
    "    train_preds = pd.Series(data = mod.predict(_X), index = _y.index, name=f'Preds')\n",
    "    \n",
    "    \n",
    "    compare_df = pd.DataFrame(data = [_y_test_observed, preds], dtype=np.float64).T\n",
    "    compare_train_df = pd.DataFrame(data = [_y, train_preds], dtype=np.float64).T\n",
    "    compare_train_df['is_train_data'] = True\n",
    "    compare_df['is_train_data'] = False\n",
    "    \n",
    "    preds_vs_obs_df = pd.concat([compare_df, compare_train_df])\n",
    "#     compare_df = compare_df.apply(lambda col: col.astype(np.float64), axis = 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    ax = fig.add_subplot(9, 8, i)\n",
    "    no_zeros = row.replace(0, np.nan).dropna() # Just for calculating some xlim that is lower than 0 for visu\n",
    "    ax.set_xlim([-no_zeros.quantile(.05), row.quantile(.95)])\n",
    "\n",
    "    s1 = sns.scatterplot(x=otu, y=preds_vs_obs_df.Preds, \n",
    "                         data=preds_vs_obs_df.loc[~preds_vs_obs_df['is_train_data']], ax=ax)\n",
    "#                      fit_reg=True, logx=False, ax=ax, truncate=False, label = 'Zeros and <q20')\n",
    "    \n",
    "#     s2 = sns.scatterplot(x=otu, y=preds_vs_obs_df.Preds,\n",
    "#                          data=preds_vs_obs_df.loc[preds_vs_obs_df['is_train_data']], ax=ax)\n",
    "\n",
    "#     l2 = sns.regplot(x=otu, y=compare_df.Preds, data=compare_df, ax=ax,\n",
    "#                 fit_reg=True, logx=False,   truncate=False\n",
    "#                          scatter_kws={'facecolors': df_full.loc[df_full['is_over_q20']].color})\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    test_rmse = round(RMSE(_y_test_observed, preds, squared=False), 5)\n",
    "    train_rmse = round(RMSE(_y, train_preds, squared=False), 5)\n",
    "    ax.set_title(f'OTU: {otu}, RMSE test: {test_rmse}, train: {train_rmse}')\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"Finished, test RMSE: {test_rmse}\")\n",
    " \n",
    "\n",
    "\n",
    "plt.savefig('RF_predictor_no_train.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train-Test split based on the partitioning to zeros and non zeros.  We train on 80% of the non-zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(70,40))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "strong_corr_dict = {}\n",
    "strongest_corr_dict = {}\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "\n",
    "mod = RF(n_jobs = 8)\n",
    "for i, (otu, row) in enumerate(list(sxsdf.iterrows())[:-1], 1):\n",
    "    \n",
    "    #Step 1 - Split into train & test data where test data inclueds: all zeros and lower 20 percentiles of the non-zeros\n",
    "    \n",
    "    no_zeros = row.replace(0, np.nan).dropna()\n",
    "    q_20 = no_zeros.quantile(.20)\n",
    "    \n",
    "    \n",
    "    # y train is the ra (relative abundance) of the 80 upper percentile of non zero samples\n",
    "    _y_train = no_zeros[no_zeros.map(lambda x: x >= q_20)]\n",
    "\n",
    "    # X train is the metabolite features of the dervied samples that were chosen\n",
    "    _X_train = mbdf[_y_train.index].T\n",
    "    \n",
    "    _y_test_observed = row[row.map(lambda x: x < q_20)]\n",
    "    _X_test = mbdf[_y_test_observed.index].T\n",
    "    \n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"For otu: {otu}, train size: {_X_train.shape[0]}, test size = {240-_X_train.shape[0]}\\n\"\n",
    "              f\"Number of zeros is: {row.apply(lambda val: val==0).sum()}\\n\"\n",
    "              f\"Number of values above 20 percentile: {len(ra_over_q20)}\")\n",
    "        \n",
    "            \n",
    "    mod.fit(_X_train, _y_train)\n",
    "    \n",
    "    \n",
    "        \n",
    "    preds = pd.Series(data = mod.predict(_X_test), index = _y_test_observed.index, name=f'Preds')\n",
    "    train_preds = pd.Series(data = mod.predict(_X_train), index = _y_train.index, name=f'Preds')\n",
    "    \n",
    "    \n",
    "    compare_df = pd.DataFrame(data = [_y_test_observed, preds], dtype=np.float64).T\n",
    "    compare_train_df = pd.DataFrame(data = [_y_train, train_preds], dtype=np.float64).T\n",
    "    compare_train_df['is_train_data'] = True\n",
    "    compare_df['is_train_data'] = False\n",
    "    preds_vs_obs_df = pd.concat([compare_df, compare_train_df])    \n",
    "    \n",
    "    ax = fig.add_subplot(9, 8, i)\n",
    "    no_zeros = row.replace(0, np.nan).dropna() # Just for calculating some xlim that is lower than 0 for visu\n",
    "    ax.set_xlim([-no_zeros.quantile(.05), row.quantile(.95)])\n",
    "    ax.set_ylim([-no_zeros.quantile(.05), 1.2*preds.quantile(.99)])\n",
    "\n",
    "    s1 = sns.scatterplot(x=otu, y=preds_vs_obs_df.Preds, \n",
    "                         data=preds_vs_obs_df.loc[~preds_vs_obs_df['is_train_data']], ax=ax)\n",
    "    \n",
    "    s2 = sns.scatterplot(x=otu, y=preds_vs_obs_df.Preds,\n",
    "                     data=preds_vs_obs_df.loc[preds_vs_obs_df['is_train_data']], ax=ax)\n",
    "    \n",
    "    test_rmse = round(RMSE(_y_test_observed, preds, squared=False), 5)\n",
    "    train_rmse = round(RMSE(_y_train, train_preds, squared=False), 5)\n",
    "    ax.set_title(f'OTU: {otu}, RMSE test: {test_rmse}, train: {train_rmse}')\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"Finished, RMSE test: {test_rmse}, train: {train_rmse}\\n\")\n",
    "\n",
    "\n",
    "plt.savefig('RF_predict_zeros_based_division.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_full.is_over_q20.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[otu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind = 'scatter', x = 'Actinobacteria;Collinsella', y='ARGININE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strongest_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_corr = corr.loc[otu,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.loc[otu,:].where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corr.loc[otu,:].where((corr.loc[otu,:] < 1) & (abs(corr.loc[otu,:]) > CORR_THRESHOLD)).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each metabolite and each specie we find the features that correlate with it while distinguishing \n",
    "# between mtabolites and species\n",
    "\n",
    "strong_bacterical_coefs = {}\n",
    "strong_metabolite_coefs = {}\n",
    "\n",
    "for idx, (name, row) in enumerate(strong_corr.iloc[0:N_sxs,:].iterrows(), 1):\n",
    "    strong_bacterical_coefs[name] = extract_high_corrs(row, idx)\n",
    "#     print(f\"Strong coeffs for {name}:\")\n",
    "#     print(strong_metabolite_coefs[name])\n",
    "    \n",
    "for idx, (name, row) in enumerate(strong_corr.iloc[N_sxs+1:,:].iterrows(), N_sxs+1):\n",
    "    strong_metabolite_coefs[name] = extract_high_corrs(row, idx)\n",
    "#     print(f\"Strong coeffs for {name}:\")\n",
    "#     print(strong_metabolite_coefs[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mbdf[ra_over_q20.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = sxs_train.astype(float).to_numpy()\n",
    "B = mb_train.astype(float).to_numpy()\n",
    "\n",
    "corr = pd.DataFrame(np.corrcoef(A, B), \n",
    "             columns = list(sxs_train.index) + list(mb_train.index),\n",
    "            index = list(sxs_train.index) + list(mb_train.index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each metabolite and each specie we find the features that correlate with it while distinguishing \n",
    "# between mtabolites and species\n",
    "\n",
    "strong_bacterical_coefs = {}\n",
    "strong_metabolite_coefs = {}\n",
    "\n",
    "for idx, (name, row) in enumerate(strong_corr.iloc[0:N_sxs,:].iterrows(), 1):\n",
    "    strong_bacterical_coefs[name] = extract_high_corrs(row, idx)\n",
    "#     print(f\"Strong coeffs for {name}:\")\n",
    "#     print(strong_metabolite_coefs[name])\n",
    "    \n",
    "for idx, (name, row) in enumerate(strong_corr.iloc[N_sxs+1:,:].iterrows(), N_sxs+1):\n",
    "    strong_metabolite_coefs[name] = extract_high_corrs(row, idx)\n",
    "#     print(f\"Strong coeffs for {name}:\")\n",
    "#     print(strong_metabolite_coefs[name])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(strong_metabolite_coefs).dropna(how='all', axis = 'columns'\n",
    "                                            ).isnull().agg({lambda row: sum(row)/len(row),\n",
    "                                                           lambda row: len(row)-sum(row)}).T.mean(axis = 'index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the metabolites have around three strong correlations (pos or neg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation of zeros based on linear regression with variables from their correlation \n",
    "dict\n",
    "Options:\n",
    "1. regression based on correlation\n",
    "2. PCA regression\n",
    "3. Lasso\n",
    "4. RF ?\n",
    "5. kNN ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 - regression based on correlation\n",
    "This might be highly costly because we have to fit a regression for each line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe_sparsity(mb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "VERBOSE = False\n",
    "X_train = mb_train.T\n",
    "X_test = mb_test.T\n",
    "for otu, coeffs in strong_bacterical_coefs.items():\n",
    "    if(VERBOSE):\n",
    "        print(f\"Fitting a correlation based regression model for {otu}.\")\n",
    "    y_train = sxs_train.loc[otu,:]\n",
    "    if (coeffs == {}):\n",
    "        if(VERBOSE):\n",
    "            print(f\"No strong correlation were found for {otu}, regressing using all metabolites.\")\n",
    "        reg = LinearRegression().fit(X_train, y_train)\n",
    "        preds = reg.predict(X_test)\n",
    "    \n",
    "    else:\n",
    "        X_train_corr = X_train[coeffs]\n",
    "        reg = LinearRegression().fit(X_train_corr, y_train)\n",
    "        X_test_corr =  X_test[coeffs]\n",
    "        preds = reg.predict(X_test_corr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(otu)\n",
    "pd.DataFrame({'preds':preds, 'true_labels':sxs_test.loc[otu,:]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have a prediction vector for every bacteria based on it's correlated metabolites or in case there are non,\n",
    "# then we predict using all metabolites. \n",
    "# Todo - gather all predictions to one dataframe and compare them to something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 - Lasso sparse regression\n",
    "This might be highly costly because we have to fit a regression for each strain sepratley.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "VERBOSE = False\n",
    "X_train = mb_train.T\n",
    "X_test = mb_test.T\n",
    "for otu, coeffs in strong_bacterical_coefs.items():\n",
    "    if(VERBOSE):\n",
    "        print(f\"Fitting a correlation based regression model for {otu}.\")\n",
    "    y_train = sxs_train.loc[otu,:]\n",
    "    \n",
    "#     print(y_train)\n",
    "    lm = Lasso()\n",
    "#     lm.fit(X_train, y_train)\n",
    "#     lm.fit([[.1, .02, -.0055], [.22, .000, -.7], [.5, .5, .5]], [.1,2.4, 10])\n",
    "#     preds = lm.predict(X_test)\n",
    "#     lm.predict([[.005, .4, .15]])\n",
    "\n",
    "    if(VERBOSE):\n",
    "        print(f\"Coeffs for {otu}: {lm.coef_}\")t\n",
    "#     preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 3 - PCA regression\n",
    "This might be highly costly because we have to fit a regression for each strain seperatley.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "VERBOSE = False\n",
    "X_train = mb_train.T\n",
    "X_test = mb_test.T\n",
    "\n",
    "for otu, coeffs in strong_bacterical_coefs.items():\n",
    "    y_train = sxs_train.loc[otu,:]\n",
    "\n",
    "    if(VERBOSE):\n",
    "        print(f\"Decomposing train data for: {otu}.\")\n",
    "    mod = PCA(n_components=50)\n",
    "    mod.fit(X_train)\n",
    "    X_train_pca = mod.components_\n",
    "    \n",
    "    reg = LinearRegression().fit(X_train_pca, y_train)\n",
    "#     X_test_pca = mod.transform(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     y_train = sxs_train.loc[otu,:]\n",
    "#     print(y_train)\n",
    "#     lm = Lasso()\n",
    "#     lm.fit(X_train, y_train)\n",
    "#     lm.fit([[.1, .02, -.0055], [.22, .000, -.7], [.5, .5, .5]], [.1,2.4, 10])\n",
    "#     preds = lm.predict(X_test)\n",
    "#     lm.predict([[.005, .4, .15]])\n",
    "\n",
    "#     if(VERBOSE):\n",
    "#         print(f\"Coeffs for {otu}: {lm.coef_}\")t\n",
    "#     preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mb_train\n",
    "X_test = mb_test\n",
    "\n",
    "mod = PCA(n_components=40)\n",
    "mod.fit(X_train)\n",
    "X_train_pca = mod.components_\n",
    "X_test_pca = mod.transform(X_test)\n",
    "\n",
    "y_train = sxs_train.loc[otu,:]\n",
    "\n",
    "# if(VERBOSE):\n",
    "#     print(f\"Decomposing train data for: {otu}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reg = LinearRegression().fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_pca)\n",
    "# ‚âà.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "mod = PCA(n_components=50)\n",
    "mod.fit(mb_train.T)\n",
    "\n",
    "\n",
    "# X_train = mb_train.T\n",
    "# X_train.head()\n",
    "# y_train = sxs_train.loc[otu,:]\n",
    "# print(y_train)\n",
    "# lm = Lasso()\n",
    "# lm.fit(X_train, y_train)\n",
    "# lm.coef_\n",
    "# lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_train.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(otu)\n",
    "pd.DataFrame({'preds':preds, 'true_labels':sxs_test.loc[otu,:]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a subset of the data\n",
    "Divide the data into 0.8:0.2 (samples) and apply this division to both the metabolites and the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sxs_train, sxs_test = train_test_split(sxsdf.T, train_size = 0.8, test_size = 0.2, shuffle=True)\n",
    "train_ids = sxs_train.T.columns.intersection(sample_ids)\n",
    "test_ids = sxs_test.T.columns.intersection(sample_ids)\n",
    "\n",
    "\n",
    "sxs_train, sxs_test = sxs_train.T, sxs_test.T\n",
    "mb_train, mb_test = mbdf.loc[:,train_ids], mbdf.loc[:,test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A.corrwith(B, drop=True, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = A.replace(0, np.nan)\n",
    "C.corrwith(B, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind1, specie in A.iterrows():\n",
    "    for ind2, metabolite in B.iterrows():\n",
    "        print(specie.corr(metabolite))\n",
    "        print(ind2, ind1)\n",
    "        \n",
    "\n",
    "# s1 = A.iloc[0,:]\n",
    "# s2 = B.iloc[0,:]\n",
    "# s2.corr(s1)\n",
    "\n",
    "# s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.corrwith(B, axis = 'columns')\n",
    "a0 = A.loc['Actinobacteria;Actinomyces',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.astype(float).corrwith(B.astype(float), axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row_name, row in B.iterrows():\n",
    "#     print(row[1])\n",
    "#     row.corr(A.loc['Actinobacteria;Actinomyces',:])\n",
    "#     print(row.corr(a0.values))\n",
    "# .2, .0, .6, .2\n",
    "    \n",
    "s1 = pd.Series({'H001':.2, 'H002':0.0, 'H003':0.6, 'H004':0.2})\n",
    "s2 = pd.Series([-0.116793,-0.382685, 0.019573, 0.202570])\n",
    "s1.corr(a0.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/d_private/OneDrive - mail.tau.ac.il/Lab/data/FRANZOSA_IBD_2019/PARSED_DATA/basic_process_reduce_sparse'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_wgs_df = pd.read_csv(f'{data_path}/WGS/taxonomic_profiles.tsv', sep='\\t', header = 0, index_col=0)\n",
    "# Drop everything but specie levels\n",
    "print(feat_wgs_df.shape)\n",
    "mask = feat_wgs_df.index.str.contains(\"s__\") & (feat_wgs_df.index.str.contains(\"t__\") == False)\n",
    "feat_wgs_filtered = feat_wgs_df.drop(feat_wgs_df[~mask].index.values, inplace=False)\n",
    "print(feat_wgs_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls $data_path/HMP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta transcriptome\n",
    "The metatranscriptomics the come with a '_pathabundance_cpm' suffix so it has to be removed first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_pathAundancies_df = pd.read_csv(f'{data_path}/Metatranscriptomics/pathabundances_3.tsv', sep='\\t', header = 0, index_col=0)\n",
    "print(feat_pathAundancies_df.shape)\n",
    "metatrans_filtered = deepcopy(feat_pathAundancies_df)\n",
    "metatrans_filtered.columns = [col.split('_pathabundance_cpm')[0] for col in metatrans_filtered.columns]\n",
    "feat_metatrans_filtered = deepcopy(metatrans_filtered)\n",
    "print(feat_metatrans_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_16s = pd.read_csv(f'{data_path}/16S/taxonomic_profiles.tsv', sep='\\t', header = 0, index_col=0)\n",
    "\n",
    "# /Users/d_private/Documents/University/Lab/data/HMP2/16S/1806/taxonomic_profiles.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_16s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabolomics\n",
    "\n",
    "The metabolomics data has a few extra columns of metadata in the beginning, icnluding method etc.  \n",
    "Shape: (81867, 552)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_meatbolomics = pd.read_csv(f'{data_path}/Metabolites/HMP2_metabolomics.csv', header = 0, index_col=0)\n",
    "# /Users/d_private/Documents/University/Lab/data/HMP2/Metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_meatbolomics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_wgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets based only common samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs_samples = set(feat_wgs_df.columns)\n",
    "sxs_samples = set(feat_16s.columns)\n",
    "metab_samples = set(feat_meatbolomics.columns[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metab_samples.intersection(metab_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_shapes(df_dict : dict) -> str:\n",
    "    res = f\"Data dimensions:\\n\"\n",
    "    for name, df in df_dict.items():\n",
    "        res += f\"{name}: {df.shape},\\t\"\n",
    "          \n",
    "#    print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the intersection between all the dataframes columns (sample ids) then filter the dataframe accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unnecessary \n",
    "#smpls_16 = list(feat_16s.columns)\n",
    "#smpls_wgs = list(feat_wgs_filtered.columns)\n",
    "#smpls_mta = list(feat_metatrans_filtered.columns)\n",
    "#smpls_mtb = list(feat_meatbolomics.columns)\n",
    "\n",
    "# Find intersection between column names - samples ids\n",
    "common_samples = feat_wgs_filtered.columns.intersection(feat_metatrans_filtered.columns)\n",
    "common_samples = common_samples.intersection(feat_meatbolomics.columns)\n",
    "\n",
    "# Filter dfs according to intersection\n",
    "comp_wgs = pd.DataFrame(feat_wgs_filtered[common_samples],)\n",
    "comp_wgs.name = 'complete_WGS'\n",
    "comp_mta = pd.DataFrame(feat_metatrans_filtered[common_samples],)\n",
    "comp_mta.name = 'complete_metatranscriptome'\n",
    "\n",
    "\n",
    "# Metabolomics data has some additional infromational columns in it so we keep them as well\n",
    "cols = feat_meatbolomics.columns[0:6].append(common_samples)\n",
    "comp_mtb = pd.DataFrame(feat_meatbolomics[cols],)\n",
    "comp_mtb.name = 'complete_metabolome'\n",
    "\n",
    "# Describe new dfs dims\n",
    "df_dict = {'WGS':comp_wgs, 'metat':comp_mta, 'metab':comp_mtb}\n",
    "print(get_data_shapes(df_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write complete dataframes to file\n",
    "print(\"Writing files\")\n",
    "for df in df_list:\n",
    "    print(df.name)\n",
    "    df.to_csv(path_or_buf=f\"{proccessed_data_path}/{df.name}.csv\")\n",
    "\n",
    "print(f\"Finished writing files to {proccessed_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_sparsity_description(df):\n",
    "    temp = df.fillna(0)\n",
    "#     print(\"Now describing dataset: \" + df.name)\n",
    "    print(\"******\")\n",
    "    zero_by_feat = temp.apply(lambda row: sum(row==0)/len(row), axis = 1)\n",
    "    print(f\"Zero by feature summary stats: {zero_by_feat.describe()}\")\n",
    "    zero_by_sample = temp.apply(lambda col: sum(col==0)/len(col), axis = 0)\n",
    "    print(f\"Zero by feature sample stats: {zero_by_sample.describe()}\")\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sum(comp_wgs.CSM5MCVN)\n",
    "# sum(comp_wgs.values == 0)\n",
    "\n",
    "get_sparsity_description(comp_wgs)\n",
    "get_sparsity_description(comp_mtb)\n",
    "get_sparsity_description(comp_mta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imputation of NaNs in metabolomics data\n",
    "For each row find it's minimum and put 90% of it instead of all NaNs\n",
    "The rational behind this is that there's some threshold that anything below it isn't counted but it still exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows of metabolites that are unclassified - NaN\n",
    "comp_mtb_only_classified = comp_mtb.dropna(subset = ['Metabolite'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The complete metabolites data has different measurement methods in it. For each measurement method we find the \n",
    "# minimal value of this method and store it.\n",
    "minmal_vals_by_method = comp_mtb_only_classified.iloc[:,6:].groupby('Method').min().apply(lambda row: row.min(), axis = 1)\n",
    "\n",
    "# Now we group according to method and replace the NaNs missing values according to the measurement method. \n",
    "# We replace NaNs with 0.9 * minimal_value for method\n",
    "comp_mtb_no_Nans = comp_mtb_only_classified.groupby('Method').apply(lambda group: group.fillna(0.9 * minmal_vals_by_method[group.name]))\n",
    "comp_mtb_no_Nans = comp_mtb_no_Nans.reset_index().set_index('Metabolite', drop=True)\n",
    "print(comp_mtb_no_Nans.shape)\n",
    "df_dict['metab'] = comp_mtb_no_Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_data_shapes(df_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Cleanning the meta-transcriptome data from unmapped/unintegrated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comp_mta_only_classified = comp_mta.iloc[2:,:]\n",
    "df_dict['metat'] = comp_mta_only_classified\n",
    "print(get_data_shapes(df_dict))\n",
    "get_sparsity_description(comp_mta_only_classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGS\n",
    "n_va = 50\n",
    "n = comp_wgs.shape[1]\n",
    "wgs_tr = comp_wgs.transpose().iloc[:-n_va,:].transpose()\n",
    "wgs_va = comp_wgs.transpose().iloc[n-n_va:,:].transpose()\n",
    "\n",
    "# Metabolome\n",
    "n = comp_mtb_no_Nans.shape[1]\n",
    "mtb_tr = comp_mtb_no_Nans.transpose().iloc[:-n_va,:].transpose()\n",
    "mtb_va = comp_mtb_no_Nans.transpose().iloc[n-n_va:,:].transpose()\n",
    "\n",
    "# Metatrascriptome\n",
    "n = comp_mta_only_classified.shape[1]\n",
    "mta_tr = comp_mta_only_classified.transpose().iloc[:-n_va,:].transpose()\n",
    "mta_va = comp_mta_only_classified.transpose().iloc[n-n_va:,:].transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Omic imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sparsity_description(wgs_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Sparse dataset for metabolomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_mtb_no_Nans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# features are columns we impute them by kNNIMpute\n",
    "\n",
    "miss_block_size = 0.3\n",
    "\n",
    "# total number of samples\n",
    "n_features, n_samples = comp_mtb_no_Nans.shape\n",
    "print(n_features, n_samples)\n",
    "\n",
    "# total number of samples with intentionally missing values\n",
    "n_samples_miss = int(0.3 * n_samples)\n",
    "n_feature_miss = int((0.3)*n_features)\n",
    "\n",
    "# Assuming the samples are iid we choose WLOG the first n_miss samples (columns) to sparsify\n",
    "mtb_tr_sparse = deepcopy(mtb_tr)\n",
    "#TODO - Add some randomness to the introduction of sparse values\n",
    "mtb_tr_sparse.iloc[n_features-n_feature_miss:, n_samples-n_samples_miss:] = 0.0\n",
    "\n",
    "print(f\"Sparsified {n_feature_miss} features (rows), and {n_samples_miss} samples (columns)\")\n",
    "print(f\"Sparsity desription: {n_feature_miss*n_samples_miss} out of {mtb_tr.size} cells sparsified. percent: {round(n_feature_miss*n_samples_miss/mtb_tr.size*100, 3)}\")\n",
    "\n",
    "# zero_rows_df = df[df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "\n",
    "# df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "# mask = sum(d) == 0\n",
    "# feat_wgs_df.loc[feat_wgs_df[mask]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-omic imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mtb_tr_sparse.iloc[row:,col:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "mtb_tr_sparse_T = mtb_tr_sparse.transpose()\n",
    "missing = mtb_tr_sparse_T.iloc[row:,col:]\n",
    "mtb_tr_sparse_T\n",
    "X = mtb_tr_sparse_T.iloc[7:row,:col]\n",
    "Y = mtb_tr_sparse_T.iloc[7:row:, col:]\n",
    "\n",
    "\n",
    "regressor = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "lmols = regressor.fit(X, Y)\n",
    "\n",
    "predicted = lmols.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "mtb_pred.iloc[row:,col:] = predicted\n",
    "rmse = mean_squared_error(mtb_pred.iloc[row:,col:], mtb_tr.transpose().iloc[row:,col:], squared=False)\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO + CV for optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# LassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "lmlas = linear_model.MultiTaskLassoCV(verbose=True, n_jobs=4).fit(X, Y)\n",
    "\n",
    "predicted_las = lmlas.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "# mtb_pred.iloc[row:,col:] = predicted_las\n",
    "rmse_las = mean_squared_error(predicted_las,true_val, squared=False)\n",
    "print(rmse, rmse_las)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet + CV for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# LassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "lm_elas = linear_model.MultiTaskElasticNetCV(verbose=True, n_jobs=4).fit(X, Y)\n",
    "\n",
    "predicted_elas = lm_elas.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "# mtb_pred.iloc[row:,col:] = predicted_las\n",
    "rmse_elas = mean_squared_error(predicted_elas,true_val, squared=False)\n",
    "print(rmse, rmse_las, rmse_elas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non parametric imputation via kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "mtb_with_nan = deepcopy(mtb_tr_sparse_T)\n",
    "mtb_with_nan.iloc[row:,col:] = np.NaN\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "\n",
    "predicted_knn = knn_imputer.fit_transform(mtb_with_nan.iloc[7:,:])\n",
    "\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "mtb_predicted_knn = deepcopy(mtb_tr_sparse_T)\n",
    "mtb_predicted_knn.iloc[7:,:] = predicted_knn\n",
    "\n",
    "rmse_knn = mean_squared_error(mtb_predicted_knn.iloc[row:,col:],true_val, squared=False)\n",
    "print(rmse, rmse_las, rmse_elas, rmse_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrative imputation based on other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Describe complete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-omic imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_tr_sparse.iloc[row:,col:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "mtb_tr_sparse_T = mtb_tr_sparse.transpose()\n",
    "missing = mtb_tr_sparse_T.iloc[row:,col:]\n",
    "mtb_tr_sparse_T\n",
    "X = mtb_tr_sparse_T.iloc[7:row,:col]\n",
    "Y = mtb_tr_sparse_T.iloc[7:row:, col:]\n",
    "\n",
    "\n",
    "regressor = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "lmols = regressor.fit(X, Y)\n",
    "\n",
    "predicted = lmols.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "mtb_pred.iloc[row:,col:] = predicted\n",
    "rmse = mean_squared_error(mtb_pred.iloc[row:,col:], mtb_tr.transpose().iloc[row:,col:], squared=False)\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO + CV for optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# LassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "lmlas = linear_model.MultiTaskLassoCV(verbose=True, n_jobs=4).fit(X, Y)\n",
    "\n",
    "predicted_las = lmlas.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "# mtb_pred.iloc[row:,col:] = predicted_las\n",
    "rmse_las = mean_squared_error(predicted_las,true_val, squared=False)\n",
    "print(rmse, rmse_las)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet + CV for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# LassoCV(*, eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False, precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=None, positive=False, random_state=None, selection='cyclic')\n",
    "row = n_samples-n_samples_miss\n",
    "col = n_features-n_feature_miss\n",
    "# rows = mtb_tr_sparse.iloc[row:,]\n",
    "# cols = mtb_tr_sparse.index[col:]\n",
    "\n",
    "lm_elas = linear_model.MultiTaskElasticNetCV(verbose=True, n_jobs=4).fit(X, Y)\n",
    "\n",
    "predicted_elas = lm_elas.predict(mtb_tr_sparse_T.iloc[row:, :col])\n",
    "# mtb_pred = mtb_tr_sparse_T\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "# mtb_pred.iloc[row:,col:] = predicted_las\n",
    "rmse_elas = mean_squared_error(predicted_elas,true_val, squared=False)\n",
    "print(rmse, rmse_las, rmse_elas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non parametric imputation via kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "mtb_with_nan = deepcopy(mtb_tr_sparse_T)\n",
    "mtb_with_nan.iloc[row:,col:] = np.NaN\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "\n",
    "predicted_knn = knn_imputer.fit_transform(mtb_with_nan.iloc[7:,:])\n",
    "\n",
    "true_val = mtb_tr.transpose().iloc[row:,col:]\n",
    "mtb_predicted_knn = deepcopy(mtb_tr_sparse_T)\n",
    "mtb_predicted_knn.iloc[7:,:] = predicted_knn\n",
    "\n",
    "rmse_knn = mean_squared_error(mtb_predicted_knn.iloc[row:,col:],true_val, squared=False)\n",
    "print(rmse, rmse_las, rmse_elas, rmse_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrative imputation based on other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparsity_description(df):\n",
    "    temp = df.fillna(0)\n",
    "    print(\"Now describing dataset:\" + df.name)\n",
    "    zero_by_feat = temp.apply(lambda row: sum(row==0)/len(row), axis = 1)\n",
    "    print(f\"Zero by feature summary stats: {zero_by_feat.describe()}\")\n",
    "    zero_by_sample = temp.apply(lambda col: sum(col==0)/len(col), axis = 0)\n",
    "    print(f\"Zero by feature sample stats: {zero_by_sample.describe()}\")\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sum(comp_wgs.CSM5MCVN)\n",
    "# sum(comp_wgs.values == 0)\n",
    "\n",
    "get_sparsity_description(comp_wgs)\n",
    "get_sparsity_description(comp_mtb)\n",
    "get_sparsity_description(comp_mta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic imputation of NaNs in metabolomics data\n",
    "For each row find it's minimum and put 90% of it instead of all NaNs\n",
    "The rational behind this is that there's some threshold that anything below it isn't counted but it still exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The complete metabolites data has different measurement methods in it. For each measurement method we find the \n",
    "# minimal value of this method and store it.\n",
    "minmal_vals_by_method = comp_mtb.groupby('Method').min().apply(lambda row: row.min(), axis = 1)\n",
    "\n",
    "# Now we group according to method and replace the NaNs missing values according to the measurement method. \n",
    "# We replace NaNs with 0.9 * minimal_value for method\n",
    "comp_mtb_no_Nans = comp_mtb.groupby('Method').apply(lambda group: group.fillna(0.9 * minmal_vals_by_method[group.name]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_mtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(feat_wgs_df.apply(lambda col: sum(col) == 0, axis = 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "zero_rows_df = df[df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "\n",
    "df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "mask = sum(d) == 0\n",
    "feat_wgs_df.loc[feat_wgs_df[mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_wgs_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(feat_wgs_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series([0,0,0])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame([[1, 2, 0], [4,5,0]]).apply(lambda col: sum(col) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/Shared/University/Lab/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_wgs_df = pd.read_csv(f'{data_path}/HMP2/WGS/taxonomic_profiles.tsv', sep='\\t', header = 0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Glance at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_wgs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feat_wgs_df.iloc[1:30, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all rows (species) that have zero counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(feat_wgs_df.apply(lambda col: sum(col) == 0, axis = 'columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "zero_rows_df = df[df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "\n",
    "df.apply(lambda row: 0 in row.values, axis=1)]\n",
    "mask = sum(d) == 0\n",
    "feat_wgs_df.loc[feat_wgs_df[mask]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "478.984px",
    "width": "350.488px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
